{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from beautifulsoup4) (2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from requests) (3.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m153.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 KB\u001b[0m \u001b[31m144.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.22.4\n",
      "  Downloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m138.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 KB\u001b[0m \u001b[31m174.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.1.3 pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 KB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.55.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m156.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from matplotlib) (2.1.3)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m201.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8\n",
      "  Downloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m199.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 KB\u001b[0m \u001b[31m145.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.0 kiwisolver-1.4.7 matplotlib-3.9.2 pillow-11.0.0 pyparsing-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.27.1-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from selenium) (2.2.3)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.7/481.7 KB\u001b[0m \u001b[31m166.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from selenium) (2024.8.30)\n",
      "Collecting websocket-client~=1.8\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 KB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from selenium) (4.12.2)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: idna in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Collecting sniffio>=1.3.0\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: exceptiongroup in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.2.2)\n",
      "Collecting attrs>=23.2.0\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 KB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sortedcontainers\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sortedcontainers, websocket-client, sniffio, pysocks, h11, attrs, wsproto, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed attrs-24.2.0 h11-0.14.0 outcome-1.3.0.post0 pysocks-1.7.1 selenium-4.27.1 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.27.0 trio-websocket-0.11.1 websocket-client-1.8.0 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4\n",
    "%pip install requests\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (4.0.2)\n",
      "Requirement already satisfied: packaging in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: python-dotenv in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: requests in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from requests->webdriver-manager) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from requests->webdriver-manager) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from requests->webdriver-manager) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hindi_llm/siddhesh/py_env/lib/python3.10/site-packages (from requests->webdriver-manager) (3.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# URL of the NPTEL archive page\n",
    "url = \"https://archive.nptel.ac.in/course.html\"\n",
    "\n",
    "\n",
    "# Send a GET request to the webpage\n",
    "response = requests.get(url)\n",
    "if response.status_code != 200:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "    return None\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isdkn\\AppData\\Local\\Temp\\ipykernel_19120\\750189163.py:76: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(executable_path=\"C:/Users/HP/Downloads/msedgedriver.exe\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully scraped and saved to 'nptel_courses_links.json'.\n"
     ]
    }
   ],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from bs4 import BeautifulSoup\n",
    "# import json\n",
    "# import time\n",
    "\n",
    "# # URL of the NPTEL archive page\n",
    "# url = \"https://archive.nptel.ac.in/course.html\"\n",
    "\n",
    "# # Set up Selenium WebDriver (Ensure you have a compatible WebDriver like chromedriver installed)\n",
    "# # driver = webdriver.Chrome() \n",
    "# # driver = webdriver.Firefox() \n",
    "# # microsoft edge\n",
    "# driver = webdriver.Edge(executable_path=\"C:/Users/HP/Downloads/msedgedriver.exe\")\n",
    "\n",
    "# try:\n",
    "#     # Open the webpage\n",
    "#     driver.get(url)\n",
    "\n",
    "#     # Wait for the dropdown to be available and set request length to 100\n",
    "#     WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, \"request_length\")))\n",
    "#     select = Select(driver.find_element(By.NAME, \"request_length\"))\n",
    "#     select.select_by_value(\"100\")\n",
    "    \n",
    "#     # Wait for the page to load the data\n",
    "#     time.sleep(3)  # Adjust sleep time as per network speed\n",
    "\n",
    "#     # Fetch the page source after setting the request length\n",
    "#     page_source = driver.page_source\n",
    "\n",
    "#     # Use BeautifulSoup to parse the page source\n",
    "#     soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "#     # Find all relevant <tr> tags with course details\n",
    "#     courses = []\n",
    "#     rows = soup.find_all(\"tr\", role=\"row\")\n",
    "    \n",
    "#     for row in rows:\n",
    "#         link_tag = row.find(\"a\", href=True)\n",
    "#         if link_tag:\n",
    "#             course_title = link_tag.text.strip()\n",
    "#             course_link = link_tag[\"href\"]\n",
    "#             # modify link as https://archive.nptel.ac.in/ + courses/128/106/128106020/\n",
    "#             course_link = \"https://archive.nptel.ac.in/\" + course_link\n",
    "\n",
    "#             courses.append({\n",
    "#                 \"title\": course_title,\n",
    "#                 \"link\": course_link\n",
    "#             })\n",
    "\n",
    "#     # Save the extracted data to a JSON file\n",
    "#     with open(\"nptel_courses_links.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(courses, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "#     print(\"Data successfully scraped and saved to 'nptel_courses_links.json'.\")\n",
    "\n",
    "# finally:\n",
    "#     # Close the WebDriver\n",
    "#     driver.quit()\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "# URL of the NPTEL archive page\n",
    "url = \"https://archive.nptel.ac.in/course.html\"\n",
    "\n",
    "# Set up Selenium WebDriver (Ensure you have a compatible WebDriver like chromedriver installed)\n",
    "driver = webdriver.Edge(executable_path=\"C:/Users/HP/Downloads/msedgedriver.exe\")\n",
    "\n",
    "try:\n",
    "    # Open the webpage\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the page to load the table\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"request\")))\n",
    "\n",
    "    # List to store all course data\n",
    "    courses = []\n",
    "\n",
    "    while True:\n",
    "        # Wait for the table to load\n",
    "        time.sleep(3)  # Adjust sleep time if needed\n",
    "\n",
    "        # Fetch the page source\n",
    "        page_source = driver.page_source\n",
    "\n",
    "        # Use BeautifulSoup to parse the page source\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "        # Find all relevant <tr> tags with course details\n",
    "        rows = soup.find_all(\"tr\", role=\"row\")\n",
    "\n",
    "        for row in rows:\n",
    "            link_tag = row.find(\"a\", href=True)\n",
    "            if link_tag:\n",
    "                course_title = link_tag.text.strip()\n",
    "                course_link = link_tag[\"href\"]\n",
    "                # Modify link to include the base URL\n",
    "                course_link = \"https://archive.nptel.ac.in/\" + course_link\n",
    "\n",
    "                courses.append({\n",
    "                    \"title\": course_title,\n",
    "                    \"link\": course_link\n",
    "                })\n",
    "\n",
    "        # Check if the \"Next\" button is available and enabled\n",
    "        try:\n",
    "            next_button = driver.find_element(By.ID, \"request_next\")\n",
    "            if \"disabled\" in next_button.get_attribute(\"class\"):\n",
    "                # Exit loop if \"Next\" button is disabled\n",
    "                break\n",
    "\n",
    "            # Click the \"Next\" button\n",
    "            next_button.click()\n",
    "        except Exception as e:\n",
    "            print(\"No more pages or error clicking 'Next':\", e)\n",
    "            break\n",
    "\n",
    "    # Save the extracted data to a JSON file\n",
    "    with open(\"nptel_courses_links_v2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(courses, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(\"Data successfully scraped and saved to 'nptel_courses_links.json'.\")\n",
    "\n",
    "finally:\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download the pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isdkn\\AppData\\Local\\Temp\\ipykernel_20232\\1947491270.py:25: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(executable_path=\"C:/Users/HP/Downloads/msedgedriver.exe\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading PDFs: Message: javascript error: {\"status\":11,\"value\":\"Element is not currently visible and may not be manipulated\"}\n",
      "  (Session info: MicrosoftEdge=131.0.2903.63)\n",
      "Stacktrace:\n",
      "\t(No symbol) [0x00007FF700826B15]\n",
      "\tMicrosoft::Applications::Events::EventProperty::empty [0x00007FF700B4F4A4+1437348]\n",
      "\tsqlite3_dbdata_init [0x00007FF700BF2DE6+643190]\n",
      "\t(No symbol) [0x00007FF70070AD3C]\n",
      "\t(No symbol) [0x00007FF70070D32C]\n",
      "\t(No symbol) [0x00007FF70070D3FF]\n",
      "\t(No symbol) [0x00007FF70074D6B2]\n",
      "\t(No symbol) [0x00007FF7007504BA]\n",
      "\t(No symbol) [0x00007FF700744039]\n",
      "\t(No symbol) [0x00007FF70076C19A]\n",
      "\t(No symbol) [0x00007FF700743437]\n",
      "\t(No symbol) [0x00007FF7007432FD]\n",
      "\t(No symbol) [0x00007FF70076C480]\n",
      "\t(No symbol) [0x00007FF700743437]\n",
      "\t(No symbol) [0x00007FF700786BFF]\n",
      "\t(No symbol) [0x00007FF70076BE03]\n",
      "\t(No symbol) [0x00007FF700742984]\n",
      "\t(No symbol) [0x00007FF700741E30]\n",
      "\t(No symbol) [0x00007FF700742571]\n",
      "\tMicrosoft::Applications::Events::EventProperty::empty [0x00007FF700AFBB34+1094964]\n",
      "\t(No symbol) [0x00007FF7008632C8]\n",
      "\tMicrosoft::Applications::Events::EventProperty::empty [0x00007FF700AFAF73+1091955]\n",
      "\tMicrosoft::Applications::Events::EventProperty::empty [0x00007FF700AFAAD9+1090777]\n",
      "\tMicrosoft::Applications::Events::ILogConfiguration::operator* [0x00007FF700900CE1+461569]\n",
      "\tMicrosoft::Applications::Events::ILogConfiguration::operator* [0x00007FF7008FCA04+444452]\n",
      "\tMicrosoft::Applications::Events::ILogConfiguration::operator* [0x00007FF7008FCB49+444777]\n",
      "\tMicrosoft::Applications::Events::ILogConfiguration::operator* [0x00007FF7008F21C6+401382]\n",
      "\tBaseThreadInitThunk [0x00007FFFDD05259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFFDE1CAF38+40]\n",
      " https://archive.nptel.ac.in/courses/116/102/116102052/\n",
      "Error downloading PDFs: Message: javascript error: {\"status\":11,\"value\":\"Element is not currently visible and may not be manipulated\"}\n",
      "  (Session info: MicrosoftEdge=131.0.2903.63)\n",
      "Stacktrace:\n",
      "\t(No symbol) [0x00007FF700826B15]\n",
      "\tMicrosoft::Applications::Events::EventProperty::empty [0x00007FF700B4F4A4+1437348]\n",
      "\tsqlite3_dbdata_init [0x00007FF700BF2DE6+643190]\n",
      "\t(No symbol) [0x00007FF70070AD3C]\n",
      "\t(No symbol) [0x00007FF70070D32C]\n",
      "\t(No symbol) [0x00007FF70070D3FF]\n",
      "\t(No symbol) [0x00007FF70074D6B2]\n",
      "\t(No symbol) [0x00007FF7007504BA]\n",
      "\t(No symbol) [0x00007FF700744039]\n",
      "\t(No symbol) [0x00007FF70076C19A]\n",
      "\t(No symbol) [0x00007FF700743437]\n",
      "\t(No symbol) [0x00007FF7007432FD]\n",
      "\t(No symbol) [0x00007FF70076C480]\n",
      "\t(No symbol) [0x00007FF700743437]\n",
      "\t(No symbol) [0x00007FF700786BFF]\n",
      "\t(No symbol) [0x00007FF70076BE03]\n",
      "\t(No symbol) [0x00007FF700742984]\n",
      "\t(No symbol) [0x00007FF700741E30]\n",
      "\t(No symbol) [0x00007FF700742571]\n",
      "\tMicrosoft::Applications::Events::EventProperty::empty [0x00007FF700AFBB34+1094964]\n",
      "\t(No symbol) [0x00007FF7008632C8]\n",
      "\tMicrosoft::Applications::Events::EventProperty::empty [0x00007FF700AFAF73+1091955]\n",
      "\tMicrosoft::Applications::Events::EventProperty::empty [0x00007FF700AFAAD9+1090777]\n",
      "\tMicrosoft::Applications::Events::ILogConfiguration::operator* [0x00007FF700900CE1+461569]\n",
      "\tMicrosoft::Applications::Events::ILogConfiguration::operator* [0x00007FF7008FCA04+444452]\n",
      "\tMicrosoft::Applications::Events::ILogConfiguration::operator* [0x00007FF7008FCB49+444777]\n",
      "\tMicrosoft::Applications::Events::ILogConfiguration::operator* [0x00007FF7008F21C6+401382]\n",
      "\tBaseThreadInitThunk [0x00007FFFDD05259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFFDE1CAF38+40]\n",
      " https://archive.nptel.ac.in/courses/128/106/128106020/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# URL to scrape\n",
    "\n",
    "\n",
    "# Directory to save downloaded PDFs\n",
    "download_dir = \"downloaded_pdfs\"\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "# ChromeDriverManager().install()\n",
    "# driver = webdriver.Chrome()\n",
    "# driver = webdriver.Chrome()  # Or use webdriver.Firefox() based on your browser\n",
    "# driver = webdriver.Firefox() \n",
    "driver = webdriver.Edge(executable_path=\"C:/Users/HP/Downloads/msedgedriver.exe\")\n",
    "\n",
    "# for course in courses:\n",
    "#     # Open the webpage\n",
    "def download_pdf(url, name):\n",
    "    download_dir = f\"downloaded_pdfs/{name}\"\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "    try:\n",
    "        # Open the webpage\n",
    "        # driver.get(course[\"link\"])  \n",
    "        driver.get(url)  \n",
    "\n",
    "        # Wait for the \"Transcripts\" tab to load and click it\n",
    "        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"a[data-toggle='tab'][href='#download_transcripts']\"))).click()\n",
    "\n",
    "        while True:\n",
    "            # Wait for the page to load the transcripts content\n",
    "            # time.sleep(3)  # Adjust sleep time as needed\n",
    "\n",
    "            # Select 100 entries in the dropdown\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, \"request1_length\")))\n",
    "            select = Select(driver.find_element(By.NAME, \"request1_length\"))\n",
    "            select.select_by_value(\"100\")\n",
    "\n",
    "            # Wait for the page to load the data\n",
    "            time.sleep(3)  # Adjust sleep time as needed\n",
    "\n",
    "            # Fetch the page source\n",
    "            page_source = driver.page_source\n",
    "\n",
    "            # Use BeautifulSoup to parse the page source\n",
    "            soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "            # Find all rows in the transcripts table\n",
    "            rows = soup.find_all(\"tr\", role=\"row\")\n",
    "\n",
    "            # Iterate through rows to find and download PDFs\n",
    "            for row in rows:\n",
    "                columns = row.find_all(\"td\")\n",
    "                if len(columns) > 2:  # Ensure the row has enough columns\n",
    "                    title = columns[1].text.strip()  # Extract title\n",
    "                    pdf_link_tag = columns[2].find(\"a\", href=True)  # Look for <a> tag in the third column\n",
    "\n",
    "                    if pdf_link_tag and \"drive.google.com\" in pdf_link_tag[\"href\"]:\n",
    "                        pdf_url = pdf_link_tag[\"href\"]\n",
    "                        pdf_filename = os.path.join(download_dir, f\"{title}.pdf\")\n",
    "\n",
    "                        # Attempt to download the PDF via Google Drive\n",
    "                        response = requests.get(pdf_url, stream=True)\n",
    "                        if response.status_code == 200:\n",
    "                            with open(pdf_filename, \"wb\") as f:\n",
    "                                for chunk in response.iter_content(chunk_size=1024):\n",
    "                                    if chunk:  # Filter out keep-alive chunks\n",
    "                                        f.write(chunk)\n",
    "                            print(f\"Downloaded: {title}\")\n",
    "                        else:\n",
    "                            print(f\"Failed to download: {title} (Status code: {response.status_code})\")\n",
    "                    # Check if the \"Next\" button is available and enabled\n",
    "            try:\n",
    "                next_button = driver.find_element(By.ID, \"request_next\")\n",
    "                if \"disabled\" in next_button.get_attribute(\"class\"):\n",
    "                    # Exit loop if \"Next\" button is disabled\n",
    "                    break\n",
    "\n",
    "                # Click the \"Next\" button\n",
    "                next_button.click()\n",
    "            except Exception as e:\n",
    "                print(\"No more pages or error clicking 'Next':\", e)\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(\"Error downloading PDFs:\", e, url)\n",
    "\n",
    "\n",
    "url = \"https://archive.nptel.ac.in/courses/116/102/116102052/\"  # Replace with the actual URL\n",
    "name = \"Introduction to Machine Learning\"\n",
    "download_pdf(url, name)\n",
    "url = \"https://archive.nptel.ac.in/courses/128/106/128106020/\"\n",
    "name = \"Introduction to Deeplearning\"\n",
    "download_pdf(url, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
